{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required dependencies \n",
    "import cv2  # for video rendering \n",
    "import dlib  # for face and landmark detection \n",
    "import imutils \n",
    "  \n",
    "# for calculating dist b/w the eye landmarks \n",
    "from scipy.spatial import distance as dist \n",
    "  \n",
    "# to get the landmark ids of the left \n",
    "# and right eyes ----you can do this  \n",
    "# manually too \n",
    "from imutils import face_utils \n",
    "  \n",
    "cam = cv2.VideoCapture() \n",
    "  \n",
    "  \n",
    "# Initializing the Models for Landmark and \n",
    "# face Detection \n",
    "detector = dlib.get_frontal_face_detector() \n",
    "landmark_predict = dlib.shape_predictor( \n",
    "    'Model/shape_predictor_68_face_landmarks.dat') \n",
    "  \n",
    "while 1: \n",
    "  \n",
    "    # If the video is finished then reset it  \n",
    "    # to the start \n",
    "    if cam.get(cv2.CAP_PROP_POS_FRAMES) == cam.get( \n",
    "      cv2.CAP_PROP_FRAME_COUNT): \n",
    "        cam.set(cv2.CAP_PROP_POS_FRAMES, 0) \n",
    "  \n",
    "    else: \n",
    "        _, frame = cam.read() \n",
    "        frame = imutils.resize(frame, width=640) \n",
    "  \n",
    "        # converting frame to gray scale to pass \n",
    "        # to detector \n",
    "        img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "          \n",
    "        # detecting the faces---# \n",
    "        faces = detector(img_gray) \n",
    "        for face in faces: \n",
    "            cv2.rectangle(frame, face[0], face[1], \n",
    "                          (200, 0, 0), 1) \n",
    "  \n",
    "        cv2.imshow(\"Video\", frame) \n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'): \n",
    "            break\n",
    "  \n",
    "cam.release() \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_EAR(eye): \n",
    "      \n",
    "    # calculate the vertical distances \n",
    "    # euclidean distance is basically  \n",
    "    # the same when you calculate the \n",
    "    # hypotenuse in a right triangle \n",
    "    y1 = dist.euclidean(eye[1], eye[5]) \n",
    "    y2 = dist.euclidean(eye[2], eye[4]) \n",
    "  \n",
    "    # calculate the horizontal distance \n",
    "    x1 = dist.euclidean(eye[0], eye[3]) \n",
    "  \n",
    "    # calculate the EAR \n",
    "    EAR = (y1+y2) / x1 \n",
    "  \n",
    "    return EAR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required dependencies \n",
    "import cv2  # for video rendering \n",
    "import dlib  # for face and landmark detection \n",
    "import imutils \n",
    "# for calculating dist b/w the eye landmarks \n",
    "from scipy.spatial import distance as dist \n",
    "# to get the landmark ids of the left and right eyes \n",
    "# you can do this manually too \n",
    "from imutils import face_utils \n",
    "  \n",
    "# from imutils import \n",
    "  \n",
    "cam = cv2.VideoCapture(0) \n",
    "\n",
    "  \n",
    "# defining a function to calculate the EAR \n",
    "def calculate_EAR(eye): \n",
    "  \n",
    "    # calculate the vertical distances \n",
    "    y1 = dist.euclidean(eye[1], eye[5]) \n",
    "    y2 = dist.euclidean(eye[2], eye[4]) \n",
    "  \n",
    "    # calculate the horizontal distance \n",
    "    x1 = dist.euclidean(eye[0], eye[3]) \n",
    "  \n",
    "    # calculate the EAR \n",
    "    EAR = (y1+y2) / x1 \n",
    "    return EAR \n",
    "  \n",
    "# Variables \n",
    "blink_thresh = 0.45\n",
    "succ_frame = 2\n",
    "count_frame = 0\n",
    "  \n",
    "# Eye landmarks \n",
    "(L_start, L_end) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"] \n",
    "(R_start, R_end) = face_utils.FACIAL_LANDMARKS_IDXS['right_eye'] \n",
    "  \n",
    "# Initializing the Models for Landmark and  \n",
    "# face Detection \n",
    "detector = dlib.get_frontal_face_detector() \n",
    "landmark_predict = dlib.shape_predictor( \n",
    "    'shape_predictor_68_face_landmarks.dat') \n",
    "while 1: \n",
    "  \n",
    "    # If the video is finished then reset it \n",
    "    # to the start \n",
    "    if cam.get(cv2.CAP_PROP_POS_FRAMES) == cam.get( \n",
    "            cv2.CAP_PROP_FRAME_COUNT): \n",
    "        cam.set(cv2.CAP_PROP_POS_FRAMES, 0) \n",
    "  \n",
    "    else: \n",
    "        _, frame = cam.read() \n",
    "        frame = imutils.resize(frame, width=640) \n",
    "  \n",
    "        # converting frame to gray scale to \n",
    "        # pass to detector \n",
    "        img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "        # detecting the faces \n",
    "        faces = detector(img_gray) \n",
    "        for face in faces: \n",
    "  \n",
    "            # landmark detection \n",
    "            shape = landmark_predict(img_gray, face) \n",
    "  \n",
    "            # converting the shape class directly \n",
    "            # to a list of (x,y) coordinates \n",
    "            shape = face_utils.shape_to_np(shape) \n",
    "  \n",
    "            # parsing the landmarks list to extract \n",
    "            # lefteye and righteye landmarks--# \n",
    "            lefteye = shape[L_start: L_end] \n",
    "            righteye = shape[R_start:R_end] \n",
    "  \n",
    "            # Calculate the EAR \n",
    "            left_EAR = calculate_EAR(lefteye) \n",
    "            right_EAR = calculate_EAR(righteye) \n",
    "  \n",
    "            # Avg of left and right eye EAR \n",
    "            avg = (left_EAR+right_EAR)/2\n",
    "            if avg < blink_thresh: \n",
    "                count_frame += 1  # incrementing the frame count \n",
    "            else: \n",
    "                if count_frame >= succ_frame: \n",
    "                    cv2.putText(frame, 'Blink Detected', (30, 30), \n",
    "                                cv2.FONT_HERSHEY_DUPLEX, 1, (0, 200, 0), 1) \n",
    "                else: \n",
    "                    count_frame = 0\n",
    "  \n",
    "        cv2.imshow(\"Video\", frame) \n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'): \n",
    "            break\n",
    "  \n",
    "cam.release() \n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
